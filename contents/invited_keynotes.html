
<h2 style="font-weight: bold; color: rgb(204, 0, 0);">EDBT/ICDT 2026 Invited Talks</h2>


<p>We are very pleased to announce the EDBT/ICDT 2026 invited speakers. </p>


<div id="reinhard">
<span style="display: block; margin-bottom: 40pt;">
    <h3><b>"Query Decompositions and All That"</b></h3>
    <h4>by 
    <b><a href="https://informatics.tuwien.ac.at/people/reinhard-pichler" target="_blank">Reinhard Pichler</a></b></h4>
    <b>TU Vienna</b><br>
    <br> 
    <p style="text-align: justify;"><b>Abstract</b>: The close relationship between Conjunctive Queries (CQs) and Constraint Satisfaction Problems (CSPs) has long been known. Nevertheless, apart from decomposition methods, research on efficient query evaluation or constraint solving algorithms has developed rather independently.
    In this talk, we illustrate how search algorithms originating from the CSP community can be fruitfully applied to query evaluation - either by further developing the original search algorithms or by combining them with query decomposition methods. It turns out that the resulting approaches may indeed lead to lower time and/or space complexity than previous query evaluation methods.</p>
    <img src="./images/photos/reinhard.jpg" alt="Reinhard Pichler" align="left" style="border: 0px solid ; margin: 0px; padding-right: 10px; width: 140px; height: 150px; object-fit: cover;" />    
    <p style="text-align: justify;"><i><b>Reinhard Pichler</b></i> is a professor at the Faculty of Informatics of the TU Wien. Prior to his position in academia he spent over a decade as software developer at Siemens. His recent research interests comprise various aspects of query answering such as decomposition methods, diversity of query answers, optimization of recursive queries, space complexity of query evaluation, etc. He has been a regular PC member of ICDT and PODS and he served as PC chair of PODS 2021. He was one of the recipients of the Best Practices in Education Award 2019 (by Informatics Europe), the Alonzo Church Award for Outstanding Contributions to Logic and Computation 2021 (by SIGLOG, EATCS, EACSL, KGS), and the PODS 2022 Best Paper Award.</p>
</span>
</div>


<div id="holger">
<span style="display: block; margin-bottom: 40pt;">
    <h3><b>"Enough with the Glue Code! Let’s Build Snap‑Fit Data System Architectures"</b></h3>
    <h4>by 
    <b><a href="https://holger.pirk.name" target="_blank">Holger Pirk</a></b></h4>
    <b>Imperial College London</b><br>
    <br> 
    <p style="text-align: justify;"><b>Abstract</b>: Data management systems have grown increasingly powerful—but also increasingly entangled. Over decades, we have “extended” databases not by principled design, but by gluing on new features: new operators, new access methods, new execution backends, new hardware support, new data models. The result is a generation of systems that are impressive in capabilities yet fragile in structure: difficult to extend, hard to reason about, and even harder to maintain. Glue code holds everything together, until it doesn’t, and a developer finds themselves changing code in 30 files to add a new optimizer rule. 
    In this keynote, I argue that it is time to move beyond this era of ad‑hoc extensibility and embrace snap‑fit architectures: database systems composed of interoperable, well‑specified, and independently evolvable components that click together cleanly—without bespoke bridges, duplicated logic, or deeply buried assumptions. I will outline the principles that make snap‑fit designs possible, drawing on lessons from operator‑level composition, modular execution kernels, and partial query evaluation. I will show how such architectures make it easier to innovate, easier to tailor systems to workloads and hardware, and easier to integrate new capabilities such as compression-aware processing and multi‑modal AI. 
    Using examples from recent work, I will illustrate how snap‑fit thinking enables us to replace brittle stacks with systems that are transparent, extensible, and built to evolve. Finally, I will offer a vision for a research agenda that treats composability not as an implementation detail—but as a first-class architectural goal for the next generation of data systems. These systems will be leaner, faster and easier to maintain.
    It’s time to stop gluing. It’s time to start building.</p>
    <img src="./images/photos/holger.jpg" alt="Holger Pirk" align="left" style="border: 0px solid ; margin: 0px; padding-right: 10px; width: 140px; height: 150px; object-fit: cover;" />    
    <p style="text-align: justify;"><i><b>Holger Pirk</b></i> is an Associate Professor in the Large‑Scale Data and Systems group at Imperial College London. His research spans all things data: analytics, transactions, systems, algorithms, data structures, processing models, and everything in between. While some of his work targets “traditional” relational databases, his broader aim is to expand the applicability of data management techniques. To this end, Holger studies Composable Database Systems—systems that are extensible to support heterogeneous workloads, data models, and hardware. This naturally leads to research at the intersection of data management, compilers, and computer architecture, with applications in areas ranging from generative modeling and graph processing to classic analytical workloads. Before joining Imperial, Holger was a Postdoctoral Associate in the Database Group at MIT CSAIL, a PhD student in the Database Architectures Group at CWI in Amsterdam, and an undergraduate in Computer Science at Humboldt‑Universität zu Berlin. Holger knows how to speak and write, as evidenced, respectively, by a CIDR Gong Show Award and a VLDB Best Paper Award.</p>
</span>
</div>

<div id="cristian">
<span style="display: block; margin-bottom: 40pt;">
    <h3><b>"The Dissection of a Complex Event Recognition Engine"</b></h3>
    <h4>by 
    <b><a href="https://criveros.ing.uc.cl" target="_blank">Cristian Riveros</a></b></h4>
    <b>PUC Chile</b><br>
    <br> 
    <p style="text-align: justify;"><b>Abstract</b>: Complex Event Recognition (CER) is a group of data management technologies that model data streams as sequences of events, where users are interested in recognizing complex events, namely, groups of events that represent critical situations in real life. Examples of complex events could include a fire detected by a sensor network in a nature reserve, an accident recognized by cameras in a smart city, or a critical social event in a social network. In these scenarios, event streams are generated continuously at high speed, and the importance of each event decays rapidly over time. To process them, a complex event recognition engine is a data management software that must efficiently process such data and alert on the presence of complex events in real time. 
    In this talk, we will present the dissection of CORE, a novel complex event recognition engine. The dissection will cover all its internal components: starting with its architecture, we will examine its query language, stream and memory management, query optimization, query evaluation, and complex event outputting. We will focus on the technical solutions and challenges of a CER engine, from both theoretical and practical perspectives. In particular, based on our understanding of its components, we will review several open research problems and possible directions for future work in complex event recognition. </p>
    <img src="./images/photos/cristian.jpg" alt="Cristian Riveros" align="left" style="border: 0px solid ; margin: 0px; padding-right: 10px; width: 140px; height: 150px; object-fit: cover;" />    
    <p style="text-align: justify;"><i><b>Cristian Riveros</b></i> is an associate professor in Computer Science at the Pontificia Universidad Católica de Chile and a researcher at the Millennium Institute Foundational Research on Data. His research interests lie in the foundations of data management systems, where he combines theoretical computer science and databases. He has made substantial contributions to efficient query processing of complex event processing systems, rule-based information extraction, and graph databases, among other areas. His research work is also related to the implementation of data management systems, leading the development of systems like REmatch, and CORE. He is actively involved in the research community, participating in the boards of several international conferences and program committees (e.g., PODS, ICDT, VLDB, ICALP).</p>
</span>
</div>

<div id="pinar">
<span style="display: block; margin-bottom: 70pt;">
    <h3><b>"Beauty & the Beast: Deep Learning & Its Resource Needs"</b></h3>
    <h4>by 
    <b><a href="https://www.pinartozun.com" target="_blank">Pınar Tözün</a></b></h4>
    <b>IT University of Copenhagen</b><br>
    <br> 
    <p style="text-align: justify;"><b>Abstract</b>: Deep learning workloads are computationally expensive, requiring the use of powerful and expensive hardware accelerators such as GPUs and TPUs. The computational footprint of training state-of-the-art deep learning models has increased 7 orders of magnitude in the last decade. In contrast, the computational capabilities of state-of-the-art GPUs have increased only by a couple of orders of magnitude, while also being underutilized in practice. As a result, to achieve more sustainable progress in the field of AI, it is essential to invest in more resource-/energy-/cost-aware solutions. This talk will discuss such solutions for end-to-end deep learning training pipelines.</p>
    <img src="./images/photos/pinar.jpg" alt="Pınar Tözün" align="left" style="border: 0px solid ; margin: 0px; padding-right: 10px; width: 140px; height: 150px; object-fit: cover;" />    
    <p style="text-align: justify;"><i><b>Pınar Tözün</b></i> is an Associate Professor and the Head of Data, Systems, and Robotics Section at IT University of Copenhagen (ITU). Before ITU, she was a research staff member at IBM Almaden Research Center. Prior to joining IBM, she received her PhD from EPFL. Her thesis received ACM SIGMOD Jim Gray Doctoral Dissertation Award Honorable Mention in 2016. Her research focuses on resource-aware machine learning, performance characterization of data-intensive systems, and scalability and efficiency of data-intensive systems on modern hardware.</p>
</span>
</div>

<div id="alon">
<span style="display: block; margin-bottom: 40pt;">
    <h3><b>"Data Management Meets Its AI Partner: Understanding the New Landscape"</b></h3>
    <h4>by 
    <b><a href="https://www.linkedin.com/in/alon-halevy-690222/" target="_blank">Alon Halevy</a></b></h4>
    <b>Google</b><br>
    <br> 
    <p style="text-align: justify;"><b>Abstract</b>: Generative AI is disrupting data management on multiple levels. It enables us to finally query structured and unstructured data in a uniform fashion, while simultaneously democratizing access to data through natural language interfaces to querying and to data-pipeline creation. Beyond that, AI enables us to substantially reimagine the complexity of questions we can ask from collections of data and the scope of decisions that data can help support. In this talk I will discuss how Google Cloud Data is innovating in these areas, as well as share ambitious ideas for us to tackle as a community. Ultimately, this talk aims to bring some order to the vibrant chaos of ideas currently being investigated in our field.</p>
    <img src="./images/photos/alon.jpg" alt="Alon Halevy" align="left" style="border: 0px solid ; margin: 0px; padding-right: 10px; width: 140px; height: 150px; object-fit: cover;" />    
    <p style="text-align: justify;"><i><b>Alon Halevy</b></i> is a Distinguished Engineer at Google Cloud, where he works on extending data management tools with GenAI capabilities. From 2019 until November 2023, he was a director at Meta’s Reality Labs Research, where he worked on Personal Digital Data, the combination of neural and symbolic techniques for data management and on Human Value Alignment. Prior to Meta, Alon was the CEO of Megagon Labs (2015-2018) and led the Structured Data Group at Google Research (2005-2015), where the team developed WebTables and Google Fusion Tables. From 1998 to 2005 he was a professor at the University of Washington, where he founded the database group. Alon is a founder of two startups, Nimble Technology and Transformic (acquired by Google in 2005). Alon co-authored two books: The Infinite Emotions of Coffee and Principles of Data Integration. In 2021 he received the Edgar F. Codd SIGMOD Innovations Award. Alon is a Fellow of the ACM and a recipient of the PECASE award and Sloan Fellowship. Together with his co-authors, he received VLDB 10-year best paper awards for the 2008 paper on WebTables and for the 1996 paper on the Information Manifold data integration system.</p>
</span>
</div>




<br>
<br>
